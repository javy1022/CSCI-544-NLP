{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Version: 3.7.9\n",
    "# Pandas Version: 1.3.5\n",
    "# Beautiful4 Soup Version: 4.11.1\n",
    "# Contractions Version: 0.0.18\n",
    "# Setuptools Version: 60.2.0\n",
    "# Symspellpy Version: 6.7.7\n",
    "# NLTK Version: 3.8.1\n",
    "# Scikit-learn Version: 1.0.2\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions as ct\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell\n",
    "import warnings\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import map_tag, WordNetLemmatizer, pos_tag\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty & duplicated rows\n",
    "def init_data(data_frame):\n",
    "    data_frame.dropna(inplace=True)\n",
    "    data_frame.drop_duplicates(inplace=True)\n",
    "    data_frame['star_rating'] = data_frame['star_rating'].astype('int')\n",
    "    return data_frame\n",
    "\n",
    "# Init spell checker object\n",
    "def init_spell_checker():\n",
    "    sym_spell_obj = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "    dictionary_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_dictionary_en_82_765.txt\"\n",
    "    )\n",
    "    bigram_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\"\n",
    "    )\n",
    "    sym_spell_obj.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "    sym_spell_obj.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
    "\n",
    "    return sym_spell_obj\n",
    "\n",
    "# Spell correct the input text\n",
    "def spell_correct(text):\n",
    "    input_term = text\n",
    "    suggestions = sym_spell.lookup_compound(\n",
    "        input_term, max_edit_distance=2, transfer_casing=True\n",
    "    )\n",
    "    return suggestions[0].term\n",
    "\n",
    "# Lemmatize the input word\n",
    "def word_lemmatization(word):\n",
    "    treebank_pos_tag = pos_tag([word])[0][1]\n",
    "    universal_pos_tag = map_tag('en-ptb', 'universal', treebank_pos_tag)\n",
    "\n",
    "    if universal_pos_tag == \"ADJ\":\n",
    "        word = wnl.lemmatize(word, wn.ADJ)\n",
    "    elif universal_pos_tag == \"VERB\":\n",
    "        word = wnl.lemmatize(word, wn.VERB)\n",
    "    elif universal_pos_tag == \"NOUN\":\n",
    "        word = wnl.lemmatize(word, wn.NOUN)\n",
    "    elif universal_pos_tag == \"ADV\":\n",
    "        word = wnl.lemmatize(word, wn.ADV)\n",
    "        word = get_adverb_lemma(word)\n",
    "\n",
    "    return word\n",
    "\n",
    "# Get an input adverb's lemma if any\n",
    "def get_adverb_lemma(word):\n",
    "    has_suggestion = False\n",
    "    param_wn_synset = word + \".r.01\"\n",
    "\n",
    "    # check if word's synset contains adverb option\n",
    "    for i in range(0, len(wn.synsets(word))):\n",
    "        if param_wn_synset == str((wn.synsets(word)[i])).split(\"\\'\")[1]:\n",
    "            has_suggestion = True\n",
    "\n",
    "    if not has_suggestion:\n",
    "        return word\n",
    "\n",
    "    # if yes and suggestion not empty then return suggestion, else return original word\n",
    "    suggest_lemma_list = wn.synset(param_wn_synset).lemmas()[0].pertainyms()\n",
    "    if len(suggest_lemma_list) > 0:\n",
    "        return suggest_lemma_list[0].name()\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "# Remove stop words and lemmatize the remaining words\n",
    "def lemmatize_non_stopwords(review_body_string):\n",
    "    word_tokens = word_tokenize(review_body_string)\n",
    "    buffer_string = \"\"\n",
    "\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            w = word_lemmatization(w)\n",
    "            buffer_string = buffer_string + w + \"　\"\n",
    "\n",
    "    buffer_string = re.sub(' +', ' ', buffer_string).strip()\n",
    "    return buffer_string\n",
    "\n",
    "# Data cleaning & preprocessing\n",
    "def data_cleaning(data_frame):\n",
    "    before_data_cleaning_reviews_total_length = 0\n",
    "    after_data_cleaning_reviews_total_length = 0\n",
    "    before_data_preprocessing_reviews_total_length = 0\n",
    "    after_data_preprocessing_reviews_total_length = 0\n",
    "\n",
    "    for i in range(0, len(data_frame)):\n",
    "\n",
    "        if data_frame['star_rating'][i] == '1' or data_frame['star_rating'][i] == '2':\n",
    "            data_frame.loc[i, ['star_rating']] = 'Class 1'\n",
    "        elif data_frame['star_rating'][i] == '3':\n",
    "            data_frame.loc[i, ['star_rating']] = 'Class 2'\n",
    "        elif data_frame['star_rating'][i] == '4' or data_frame['star_rating'][i] == '5':\n",
    "            data_frame.loc[i, ['star_rating']] = 'Class 3'\n",
    "\n",
    "        review_text = data_frame['review_body'][i]\n",
    "        before_data_cleaning_reviews_total_length = before_data_cleaning_reviews_total_length + len(review_text)\n",
    "\n",
    "        # remove un-wanted html tags\n",
    "        if BeautifulSoup(review_text, \"html.parser\").find():\n",
    "            review_text = BeautifulSoup(review_text, \"html.parser\").get_text(\"　\")\n",
    "\n",
    "        # spell correction\n",
    "        review_text = spell_correct(review_text)\n",
    "\n",
    "        # text extend contractions\n",
    "        review_text = ct.fix(review_text)\n",
    "\n",
    "        # remove non-alphabetical chars\n",
    "        regex = re.compile('[^a-zA-Z]')\n",
    "        review_text = regex.sub(' ', review_text)\n",
    "\n",
    "        # convert to lower case\n",
    "        review_text = review_text.lower().strip()\n",
    "        review_text = \" \".join(review_text.split())\n",
    "\n",
    "        # end of data cleaning, before data processing\n",
    "        after_data_cleaning_reviews_total_length = after_data_cleaning_reviews_total_length + len(review_text)\n",
    "\n",
    "        # start of data processing\n",
    "        before_data_preprocessing_reviews_total_length = before_data_preprocessing_reviews_total_length + len(\n",
    "            review_text)\n",
    "        review_text = lemmatize_non_stopwords(review_text)\n",
    "        # end of data processing\n",
    "        review_text = \" \".join(review_text.split())\n",
    "        after_data_preprocessing_reviews_total_length = after_data_preprocessing_reviews_total_length + len(review_text)\n",
    "\n",
    "        data_frame.loc[i, ['review_body']] = review_text\n",
    "\n",
    "    print(\"Average length of reviews before data cleaning: \" + str(before_data_cleaning_reviews_total_length / len(\n",
    "        data_frame)) + \", Average length of reviews after data cleaning: \" + str(\n",
    "        after_data_cleaning_reviews_total_length / len(data_frame)))\n",
    "    print(\"Average length of reviews before data preprocessing: \" + str(\n",
    "        before_data_preprocessing_reviews_total_length / len(\n",
    "            data_frame)) + \", Average length of reviews after data preprocessing: \" + str(\n",
    "        after_data_preprocessing_reviews_total_length / len(data_frame)))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return data_frame\n",
    "\n",
    "# Print the training result\n",
    "def generate_report(y_test, y_pred):\n",
    "    report = classification_report(y_test, y_pred, zero_division=1, output_dict=True)\n",
    "    print(\"Class 1 Precision: \" + str(report['Class 1']['precision']) + \", Class 1 Recall: \" + str(\n",
    "        report['Class 1']['recall']) + \", Class 1 f1-score: \" + str(report['Class 1']['f1-score']))\n",
    "    print(\"Class 2 Precision: \" + str(report['Class 2']['precision']) + \", Class 2 Recall: \" + str(\n",
    "        report['Class 2']['recall']) + \", Class 2 f1-score: \" + str(report['Class 2']['f1-score']))\n",
    "    print(\"Class 3 Precision: \" + str(report['Class 3']['precision']) + \", Class 3 Recall: \" + str(\n",
    "        report['Class 3']['recall']) + \", Class 3 f1-score: \" + str(report['Class 3']['f1-score']))\n",
    "    print(\"Average Precision: \" + str(report['macro avg']['precision']) + \", Averagage Recall: \" + str(\n",
    "        report['macro avg']['recall']) + \", Averagage f1-score: \" + str(\n",
    "        report['macro avg']['f1-score']))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "RANDOM_SAMPLE_SIZE = 20000\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "sym_spell = init_spell_checker()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wnl = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from cache. (data.pkl was generated by reading the given Amazon's dataset provided in HW1 description)\n",
    "df = pd.read_pickle(\"./data.pkl\")\n",
    "df = init_data(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form three classes and select 20000 reviews randomly from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 3-classes and concat into 1\n",
    "class1_df = df[df['star_rating'] <= 2].sample(RANDOM_SAMPLE_SIZE)\n",
    "class2_df = df[df['star_rating'] == 3].sample(RANDOM_SAMPLE_SIZE)\n",
    "class3_df = df[df['star_rating'] >= 4].sample(RANDOM_SAMPLE_SIZE)\n",
    "\n",
    "balanced_df = pd.concat([class1_df, class2_df, class3_df]).reset_index(drop=True)\n",
    "balanced_df['star_rating'] = balanced_df['star_rating'].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Pre-processing\n",
    "### 1.  Remove un-wanted Html tags\n",
    "### 2.  Spell corrections\n",
    "### 3.  Text contractions\n",
    "### 4.  Remove non-alphabetical chars\n",
    "### 5.  Convert to lower cases\n",
    "### 6.  Remove stop words\n",
    "### 7.  Lemmatisation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of reviews before data cleaning: 278.5658833333333, Average length of reviews after data cleaning: 269.23761666666667\n",
      "Average length of reviews before data preprocessing: 269.23761666666667, Average length of reviews after data preprocessing: 154.18928333333332\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_balanced_df = data_cleaning(balanced_df)\n",
    " # cleaned_balanced_df cache\n",
    "cleaned_balanced_df.to_pickle('cleaned_balanced_df_official.pkl')\n",
    "cleaned_balanced_df = pd.read_pickle(\"./cleaned_balanced_df_official.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf feacture matrix\n",
    "tf_idf = TfidfVectorizer(lowercase=False, ngram_range=(1, 5))\n",
    "tf_idf_result = tf_idf.fit_transform(cleaned_balanced_df['review_body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(tf_idf_result, cleaned_balanced_df['star_rating'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 Precision: 0.6571160169093471, Class 1 Recall: 0.6856162705219309, Class 1 f1-score: 0.671063676699844\n",
      "Class 2 Precision: 0.5603917301414582, Class 2 Recall: 0.5175879396984925, Class 2 f1-score: 0.5381400208986415\n",
      "Class 3 Precision: 0.707083128381702, Class 3 Recall: 0.7298806803757298, Class 3 f1-score: 0.7183010618363522\n",
      "Average Precision: 0.6415302918108358, Averagage Recall: 0.6443616301987177, Averagage f1-score: 0.6425015864782794\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Perceptron Model & generate training report\n",
    "clf_perceptron = Perceptron()\n",
    "clf_perceptron = clf_perceptron.fit(X_train, y_train)\n",
    "y_pred_perceptron = clf_perceptron.predict(X_test)\n",
    "generate_report(y_test, y_pred_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 Precision: 0.7024064808196331, Class 1 Recall: 0.7223719676549866, Class 1 f1-score: 0.7122493355883065\n",
      "Class 2 Precision: 0.6075845012366035, Class 2 Recall: 0.5555276381909547, Class 2 f1-score: 0.5803911274445465\n",
      "Class 3 Precision: 0.7346301633045149, Class 3 Recall: 0.7765930439197766, Class 3 f1-score: 0.755029001604344\n",
      "Average Precision: 0.6815403817869171, Averagage Recall: 0.6848308832552393, Averagage f1-score: 0.682556488212399\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM Linear Model & generate training report\n",
    "clf_linear_svc = LinearSVC(loss='hinge')\n",
    "clf_linear_svc = clf_linear_svc.fit(X_train, y_train)\n",
    "y_pred_linear_svc = clf_linear_svc.predict(X_test)\n",
    "generate_report(y_test, y_pred_linear_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 Precision: 0.700441609421001, Class 1 Recall: 0.699583435432492, Class 1 f1-score: 0.7000122594090965\n",
      "Class 2 Precision: 0.5834348355663824, Class 2 Recall: 0.6017587939698492, Class 2 f1-score: 0.5924551638837353\n",
      "Class 3 Precision: 0.7512437810945274, Class 3 Recall: 0.7283574511297284, Class 3 f1-score: 0.7396236143335911\n",
      "Average Precision: 0.6783734086939702, Averagage Recall: 0.6765665601773566, Averagage f1-score: 0.6773636792088076\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model & generate training report\n",
    "clf_logistic_regression = LogisticRegression(solver='sag')\n",
    "clf_logistic_regression = clf_logistic_regression.fit(X_train, y_train)\n",
    "y_pred_logistic_regression = clf_logistic_regression.predict(X_test)\n",
    "generate_report(y_test, y_pred_logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 Precision: 0.7267833109017496, Class 1 Recall: 0.6616025483950012, Class 1 f1-score: 0.6926629040533607\n",
      "Class 2 Precision: 0.573621103117506, Class 2 Recall: 0.6010050251256281, Class 2 f1-score: 0.5869938650306749\n",
      "Class 3 Precision: 0.7297691373025517, Class 3 Recall: 0.7623762376237624, Class 3 f1-score: 0.7457164142041223\n",
      "Average Precision: 0.6767245171072691, Averagage Recall: 0.6749946037147971, Averagage f1-score: 0.675124394429386\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train MultinomialNB Model & generate training report\n",
    "clf_multinomial_nb = MultinomialNB(fit_prior=False)\n",
    "clf_multinomial_nb = clf_multinomial_nb.fit(X_train, y_train)\n",
    "y_pred_multinomial_nb = clf_multinomial_nb.predict(X_test)\n",
    "generate_report(y_test, y_pred_multinomial_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authorship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Che Wei Wu\n",
    "Date: Jan 24, 2023\n",
    "Description: The source code for USC_CSCI544_SPRING23_HW1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
