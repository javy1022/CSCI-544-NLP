{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries"
      ],
      "metadata": {
        "id": "J6uHNQo3thmc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y6aDJpCPtM3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1158969-df3f-4a6e-9e39-352f3e8beebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-2.0.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.5/104.5 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "import gensim.downloader as api\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "!pip install contractions\n",
        "import contractions as ct\n",
        "import re\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Word2vec Model"
      ],
      "metadata": {
        "id": "Izo4tasbjrVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "id": "Mxm2r2VPjxhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3496b8e-542f-48d8-c1b9-8cd0bae64e7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Functions"
      ],
      "metadata": {
        "id": "sNKg-Wk-grZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_data(data_frame):\n",
        "    data_frame.dropna(inplace=True)\n",
        "    data_frame.drop_duplicates(inplace=True)\n",
        "    data_frame['star_rating'] = data_frame['star_rating'].astype('int')\n",
        "    return data_frame"
      ],
      "metadata": {
        "id": "Fp0l3DhQgwnQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_cleaning(data_frame):\n",
        "    for i in range(0, len(data_frame)):\n",
        "        if data_frame['star_rating'][i] == '1' or data_frame['star_rating'][i] == '2':\n",
        "            data_frame.loc[i, ['star_rating']] = 'Class 1'\n",
        "        elif data_frame['star_rating'][i] == '3':\n",
        "            data_frame.loc[i, ['star_rating']] = 'Class 2'\n",
        "        elif data_frame['star_rating'][i] == '4' or data_frame['star_rating'][i] == '5':\n",
        "            data_frame.loc[i, ['star_rating']] = 'Class 3'\n",
        "\n",
        "        review_text = data_frame['review_body'][i]\n",
        "        # remove un-wanted html tags\n",
        "        if BeautifulSoup(review_text, \"html.parser\").find():\n",
        "            review_text = BeautifulSoup(review_text, \"html.parser\").get_text(\"　\")\n",
        "        # text extend contractions\n",
        "        review_text = ct.fix(review_text)\n",
        "        # remove non-alphabetical chars\n",
        "        regex = re.compile('[^a-zA-Z]')\n",
        "        review_text = regex.sub(' ', review_text)\n",
        "        # convert to lower case\n",
        "        review_text = review_text.lower().strip()\n",
        "        review_text = \" \".join(review_text.split())\n",
        "        # end of data processing\n",
        "        review_text = \" \".join(review_text.split())\n",
        "        data_frame.loc[i, ['review_body']] = review_text\n",
        "     \n",
        "    return data_frame"
      ],
      "metadata": {
        "id": "7qBEB2rbrGLJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialization"
      ],
      "metadata": {
        "id": "SJjEbxDpgDbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
        "RANDOM_SAMPLE_SIZE = 20000\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
        "\n"
      ],
      "metadata": {
        "id": "Erwe56YOfY9-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare Balanced Dataset"
      ],
      "metadata": {
        "id": "ORd-eXhXlpnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading data\n",
        "df = pd.read_pickle(\"/content/drive/MyDrive/Dataset/data.pkl\")\n",
        "df = init_data(df).reset_index(drop=True)\n",
        "\n",
        "# 3-classes dataset\n",
        "class1_df = df[df['star_rating'] <= 2].sample(RANDOM_SAMPLE_SIZE)\n",
        "class2_df = df[df['star_rating'] == 3].sample(RANDOM_SAMPLE_SIZE)\n",
        "class3_df = df[df['star_rating'] >= 4].sample(RANDOM_SAMPLE_SIZE)\n",
        "\n",
        "balanced_df = pd.concat([class1_df, class2_df, class3_df]).reset_index(drop=True)\n",
        "balanced_df['star_rating'] = balanced_df['star_rating'].astype('string')\n",
        "cleaned_balanced_df = data_cleaning(balanced_df)\n",
        "print(cleaned_balanced_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdT_M4WOlxZT",
        "outputId": "238b84b8-21f2-431c-daae-2bc4af29f59d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      star_rating                                        review_body\n",
            "0         Class 1  these were almost impossible to apply to my na...\n",
            "1         Class 1  i bought this only because it said there was n...\n",
            "2         Class 1  this dryer is super noisy even for a hair blow...\n",
            "3         Class 1  purchased this product several weeks ago looke...\n",
            "4         Class 1  i have not used this product i received it tod...\n",
            "...           ...                                                ...\n",
            "59995     Class 3  i have only used this once but was veery happy...\n",
            "59996     Class 3  broguht this for my mom she loves liz claiborn...\n",
            "59997     Class 3  i had my doubts about these press on nail poli...\n",
            "59998     Class 3  i am a newbie to the manly art of wet shaving ...\n",
            "59999     Class 3             have not worn yet however very pleased\n",
            "\n",
            "[60000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2a"
      ],
      "metadata": {
        "id": "VFVTb25Gy-3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sims = wv.most_similar(positive=['king', 'woman'], negative=['man'])\n",
        "print(sims)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llGJOfcO9D3Z",
        "outputId": "29e10142-4522-45e8-9cc7-808ba758c583"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.7118192911148071), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321243286133), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.518113374710083), ('sultan', 0.5098593235015869), ('monarchy', 0.5087411999702454)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2b"
      ],
      "metadata": {
        "id": "FI-ZqGu4FP_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = cleaned_balanced_df[\"review_body\"].tolist()\n",
        "sentences_training = [index.split() for index in sentences ]\n",
        "# Train Word2vec model with Amazon review data\n",
        "my_word2vec_model = gensim.models.Word2Vec(sentences_training , size=300, window=13, min_count=9)\n"
      ],
      "metadata": {
        "id": "d6vQkLkPFVY9"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sims = my_word2vec_model.most_similar(positive=['worst','bad'])\n",
        "print(sims)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvNgc7UDWuU4",
        "outputId": "e76b8ca1-14f6-49ef-8fe0-82b2f27cf8d3"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('terrible', 0.6618835926055908), ('horrible', 0.5968073606491089), ('best', 0.536505937576294), ('awful', 0.528404712677002), ('greatest', 0.49852627515792847), ('amazing', 0.4964771568775177), ('real', 0.44130241870880127), ('good', 0.436043381690979), ('seriously', 0.42813795804977417), ('funny', 0.4183085858821869)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-96-53cf13ebc3c2>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  sims = my_word2vec_model.most_similar(positive=['worst','bad'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#check GPU and Memory"
      ],
      "metadata": {
        "id": "ClEHmHki8xL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "tUWX9upO2IZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcc8e23-70a0-47c0-8cc7-a9e3c2a6fd3d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n",
            "Your runtime has 37.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    }
  ]
}