{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries"
      ],
      "metadata": {
        "id": "J6uHNQo3thmc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "Y6aDJpCPtM3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d8bb44-51ad-4863-d49c-5ea55a3ad571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.8/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.8/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "!pip install contractions\n",
        "import contractions as ct\n",
        "import re\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Word2vec Model"
      ],
      "metadata": {
        "id": "Izo4tasbjrVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "id": "Mxm2r2VPjxhN"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Functions"
      ],
      "metadata": {
        "id": "sNKg-Wk-grZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_data(data_frame):\n",
        "    data_frame.dropna(inplace=True)\n",
        "    data_frame.drop_duplicates(inplace=True)\n",
        "    data_frame['star_rating'] = data_frame['star_rating'].astype('int')\n",
        "    return data_frame"
      ],
      "metadata": {
        "id": "Fp0l3DhQgwnQ"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_cleaning(data_frame):\n",
        "    for i in range(0, len(data_frame)):\n",
        "        if data_frame['star_rating'][i] == '1' or data_frame['star_rating'][i] == '2':\n",
        "            data_frame.loc[i, ['star_rating']] = 'Class 1'\n",
        "        elif data_frame['star_rating'][i] == '3':\n",
        "            data_frame.loc[i, ['star_rating']] = 'Class 2'\n",
        "        elif data_frame['star_rating'][i] == '4' or data_frame['star_rating'][i] == '5':\n",
        "            data_frame.loc[i, ['star_rating']] = 'Class 3'\n",
        "\n",
        "        review_text = data_frame['review_body'][i]\n",
        "        # remove un-wanted html tags\n",
        "        if BeautifulSoup(review_text, \"html.parser\").find():\n",
        "            review_text = BeautifulSoup(review_text, \"html.parser\").get_text(\"ã€€\")\n",
        "        # text extend contractions\n",
        "        review_text = ct.fix(review_text)\n",
        "        # remove non-alphabetical chars\n",
        "        regex = re.compile('[^a-zA-Z]')\n",
        "        review_text = regex.sub(' ', review_text)\n",
        "        # convert to lower case\n",
        "        review_text = review_text.lower().strip()\n",
        "        review_text = \" \".join(review_text.split())\n",
        "        # end of data processing\n",
        "        review_text = \" \".join(review_text.split())\n",
        "        # replace empty string with numpy's nan datatype\n",
        "        if review_text != \"\":                  \n",
        "            data_frame.loc[i, ['review_body']] = review_text\n",
        "        else:\n",
        "            data_frame.loc[i, ['review_body']] = np.nan\n",
        "    return data_frame"
      ],
      "metadata": {
        "id": "7qBEB2rbrGLJ"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prep(data):\n",
        "    prepared_data = []\n",
        "    for i in range (0,len(data)):\n",
        "        words_list = data[i].split()\n",
        "        vector_sum = np.zeros((300,))\n",
        "        total_word = len(words_list)\n",
        "        for word in words_list:\n",
        "            if word in wv.vocab:\n",
        "                vector_sum = vector_sum + wv[word]         \n",
        "        prepared_data.append(vector_sum/total_word)\n",
        "        \n",
        "    return np.array(prepared_data)"
      ],
      "metadata": {
        "id": "uD_VePw9bpDi"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the training result\n",
        "def generate_report(y_test, y_pred):\n",
        "    report = classification_report(y_test, y_pred, zero_division=1, output_dict=True)\n",
        "    print(\"Class 1 Precision: \" + str(report['Class 1']['precision']) + \", Class 1 Recall: \" + str(\n",
        "        report['Class 1']['recall']) + \", Class 1 f1-score: \" + str(report['Class 1']['f1-score']))\n",
        "    print(\"Class 2 Precision: \" + str(report['Class 2']['precision']) + \", Class 2 Recall: \" + str(\n",
        "        report['Class 2']['recall']) + \", Class 2 f1-score: \" + str(report['Class 2']['f1-score']))\n",
        "    print(\"Class 3 Precision: \" + str(report['Class 3']['precision']) + \", Class 3 Recall: \" + str(\n",
        "        report['Class 3']['recall']) + \", Class 3 f1-score: \" + str(report['Class 3']['f1-score']))\n",
        "    print(\"Average Precision: \" + str(report['macro avg']['precision']) + \", Averagage Recall: \" + str(\n",
        "        report['macro avg']['recall']) + \", Averagage f1-score: \" + str(\n",
        "        report['macro avg']['f1-score']))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "uNfflN3GClrH"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialization"
      ],
      "metadata": {
        "id": "SJjEbxDpgDbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SAMPLE_SIZE = 20000\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
        "\n"
      ],
      "metadata": {
        "id": "Erwe56YOfY9-"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare Balanced Dataset"
      ],
      "metadata": {
        "id": "ORd-eXhXlpnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading data\n",
        "df = pd.read_pickle(\"/content/drive/MyDrive/Dataset/data.pkl\")\n",
        "df = init_data(df).reset_index(drop=True)\n",
        "\n",
        "# 3-classes dataset\n",
        "class1_df = df[df['star_rating'] <= 2].sample(RANDOM_SAMPLE_SIZE)\n",
        "class2_df = df[df['star_rating'] == 3].sample(RANDOM_SAMPLE_SIZE)\n",
        "class3_df = df[df['star_rating'] >= 4].sample(RANDOM_SAMPLE_SIZE)\n",
        "\n",
        "balanced_df = pd.concat([class1_df, class2_df, class3_df]).reset_index(drop=True)\n",
        "balanced_df['star_rating'] = balanced_df['star_rating'].astype('string')\n",
        "cleaned_balanced_df = data_cleaning(balanced_df)\n",
        "cleaned_balanced_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "DdT_M4WOlxZT"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2a"
      ],
      "metadata": {
        "id": "VFVTb25Gy-3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 examples using word2vec-google-news-300\n",
        "example_1 = wv.most_similar(positive=['ice','sport'], negative=['walk'])\n",
        "example_2 = wv.most_similar(positive=['gas', 'dangerous'], negative=['stable'])\n",
        "example_3 = wv.most_similar(positive=['cold', 'rain'], negative=['sun'])\n",
        "print(\"ice + sport - walk ~= \" + str(example_1[0]))\n",
        "print(\"gas + dangerous - stable ~= \" + str(example_2[0]))\n",
        "print(\"cold + rain - sun ~= \" + str(example_3[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llGJOfcO9D3Z",
        "outputId": "8e9dde39-0210-48ab-ff3e-bd13405ed0eb"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ice + sport - walk ~= ('hockey', 0.5072677135467529)\n",
            "gas + dangerous - stable ~= ('natural_gas', 0.4578143358230591)\n",
            "cold + rain - sun ~= ('wet_weather', 0.5952470302581787)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2b"
      ],
      "metadata": {
        "id": "FI-ZqGu4FP_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = cleaned_balanced_df[\"review_body\"].tolist()\n",
        "sentences_training = [index.split() for index in sentences ]\n",
        "# Train Word2vec model with Amazon review data\n",
        "my_word2vec = gensim.models.Word2Vec(sentences_training , size=300, window=13, min_count=9)\n"
      ],
      "metadata": {
        "id": "d6vQkLkPFVY9"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 examples using provided Amazon review\n",
        "example_1 = my_word2vec.wv.most_similar(positive=['ice','sport'], negative=['walk'])\n",
        "example_2 = my_word2vec.wv.most_similar(positive=['gas', 'dangerous'], negative=['stable'])\n",
        "example_3 = my_word2vec.wv.most_similar(positive=['cold', 'rain'], negative=['sun'])\n",
        "print(\"ice + sport - walk ~= \" + str(example_1[0]))\n",
        "print(\"gas + dangerous - stable ~= \" + str(example_2[0]))\n",
        "print(\"cold + rain - sun ~= \" + str(example_3[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvNgc7UDWuU4",
        "outputId": "40cf499c-bc12-43da-ce4d-cd18d0a129d5"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ice + sport - walk ~= ('benzyl', 0.7632110118865967)\n",
            "gas + dangerous - stable ~= ('consumers', 0.6139011383056641)\n",
            "cold + rain - sun ~= ('toilet', 0.665246307849884)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3"
      ],
      "metadata": {
        "id": "O6pboK305N_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Split dataset into Training and Testing Set"
      ],
      "metadata": {
        "id": "m1Xjd3tX8AC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(cleaned_balanced_df['review_body'], cleaned_balanced_df['star_rating'], test_size=0.2)"
      ],
      "metadata": {
        "id": "rfS9-Wlg5RRj"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convert Datasets to Correct Format"
      ],
      "metadata": {
        "id": "BjnjmlLdI_0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_np = data_prep(X_train.to_numpy()) \n",
        "X_test_np = data_prep(X_test.to_numpy()) \n",
        "y_train_np = y_train.to_numpy()\n",
        "y_test_np =  y_test.to_numpy()"
      ],
      "metadata": {
        "id": "olt4nAY-8fYu"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Perceptron"
      ],
      "metadata": {
        "id": "yorHSUWzueGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_perceptron = Perceptron()\n",
        "clf_perceptron = clf_perceptron.fit(X_train_np, y_train_np)\n",
        "y_pred_perceptron = clf_perceptron.predict(X_test_np)\n",
        "generate_report(y_test_np, y_pred_perceptron)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrII3Njn59sB",
        "outputId": "32a9eebe-516b-4078-b941-9ebb595fe500"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 Precision: 0.7178147268408551, Class 1 Recall: 0.3783174762143215, Class 1 f1-score: 0.49549106410887034\n",
            "Class 2 Precision: 0.414054426455391, Class 2 Recall: 0.8945671049367403, Class 2 f1-score: 0.5660910518053376\n",
            "Class 3 Precision: 0.8968723584108199, Class 3 Recall: 0.2671198388721047, Class 3 f1-score: 0.411639185257032\n",
            "Average Precision: 0.6762471705690221, Averagage Recall: 0.5133348066743889, Averagage f1-score: 0.49107376705708\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Train Linear SVC"
      ],
      "metadata": {
        "id": "R86eteEjui1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_linear_svc = LinearSVC()\n",
        "clf_linear_svc = clf_linear_svc.fit(X_train_np, y_train_np)\n",
        "y_pred_linear_svc = clf_linear_svc.predict(X_test_np)\n",
        "generate_report(y_test_np, y_pred_linear_svc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIOVPay6ul8Y",
        "outputId": "9e0f6b48-a6f9-43a0-994c-260db643f158"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 Precision: 0.6594185194234058, Class 1 Recall: 0.6757636454682023, Class 1 f1-score: 0.6674910349944355\n",
            "Class 2 Precision: 0.586355089981198, Class 2 Recall: 0.5415529645249317, Class 2 f1-score: 0.5630642249161723\n",
            "Class 3 Precision: 0.7060511839272902, Class 3 Recall: 0.743202416918429, Class 3 f1-score: 0.7241506194039005\n",
            "Average Precision: 0.6506082644439647, Averagage Recall: 0.6535063423038544, Averagage f1-score: 0.6515686264381694\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#check GPU and Memory"
      ],
      "metadata": {
        "id": "ClEHmHki8xL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "tUWX9upO2IZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83683a92-9fc6-495a-ddac-d979eefae314"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n",
            "Your runtime has 37.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    }
  ]
}