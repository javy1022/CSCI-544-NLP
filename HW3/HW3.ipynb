{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6uHNQo3thmc"
      },
      "source": [
        "#Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6aDJpCPtM3Q",
        "outputId": "98b6e24a-9127-42dd-8f44-3aa98dd6f535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting symspellpy\n",
            "  Downloading symspellpy-6.7.7-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting editdistpy>=0.1.3\n",
            "  Downloading editdistpy-0.1.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.9/126.9 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: editdistpy, symspellpy\n",
            "Successfully installed editdistpy-0.1.3 symspellpy-6.7.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-2.0.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.5/104.5 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "!pip install symspellpy\n",
        "from symspellpy import SymSpell\n",
        "!pip install contractions\n",
        "import contractions\n",
        "import pkg_resources\n",
        "import contractions as ct\n",
        "import re\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izo4tasbjrVn"
      },
      "source": [
        "#Load Word2vec Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxm2r2VPjxhN",
        "outputId": "7232c2ff-320f-4a83-8f6f-428c06a50232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[====----------------------------------------------] 8.9% 148.2/1662.8MB downloaded"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "wv = api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNKg-Wk-grZs"
      },
      "source": [
        "#Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp0l3DhQgwnQ"
      },
      "outputs": [],
      "source": [
        "def init_data(data_frame):\n",
        "    data_frame.dropna(inplace=True)\n",
        "    data_frame.drop_duplicates(inplace=True)\n",
        "    data_frame['star_rating'] = data_frame['star_rating'].astype('int')\n",
        "    return data_frame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_spell_checker():\n",
        "    sym_spell_obj = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "    dictionary_path = pkg_resources.resource_filename(\n",
        "        \"symspellpy\", \"frequency_dictionary_en_82_765.txt\"\n",
        "    )\n",
        "    bigram_path = pkg_resources.resource_filename(\n",
        "        \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\"\n",
        "    )\n",
        "    sym_spell_obj.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "    sym_spell_obj.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
        "\n",
        "    return sym_spell_obj"
      ],
      "metadata": {
        "id": "uJJRcbXq0AhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spell_correct(text):\n",
        "    input_term = text\n",
        "    suggestions = sym_spell.lookup_compound(\n",
        "        input_term, max_edit_distance=2, transfer_casing=True\n",
        "    )\n",
        "    return suggestions[0].term"
      ],
      "metadata": {
        "id": "4p80gPqv0BS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exclude_words_not_in_w2v(review_body_string):\n",
        "    word_list = review_body_string.split()\n",
        "    buffer_string = \"\"\n",
        "\n",
        "    for w in word_list:\n",
        "        if w in wv.vocab:\n",
        "            buffer_string = buffer_string + w + \" \"\n",
        "\n",
        "    buffer_string = re.sub(' +', ' ', buffer_string).strip()\n",
        "    return buffer_string"
      ],
      "metadata": {
        "id": "4hVAizQn3bzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qBEB2rbrGLJ"
      },
      "outputs": [],
      "source": [
        "def data_cleaning(data_frame):\n",
        "    for i in range(0, len(data_frame)):\n",
        "        if data_frame['star_rating'][i] == 1 or data_frame['star_rating'][i] == 2:\n",
        "            data_frame.loc[i, ['star_rating']] = 0\n",
        "        elif data_frame['star_rating'][i] == 3:\n",
        "            data_frame.loc[i, ['star_rating']] = 1\n",
        "        elif data_frame['star_rating'][i] == 4 or data_frame['star_rating'][i] == 5:\n",
        "            data_frame.loc[i, ['star_rating']] = 2\n",
        "\n",
        "        review_text = data_frame['review_body'][i]\n",
        "        review_text = \" \".join(review_text.split())\n",
        "        # remove un-wanted html tags\n",
        "        if BeautifulSoup(review_text, \"html.parser\").find():\n",
        "            review_text = BeautifulSoup(review_text, \"html.parser\").get_text(\"　\")\n",
        "            review_text = \" \".join(review_text.split())\n",
        "        # spell correction\n",
        "        review_text = spell_correct(review_text)\n",
        "        # text extend contractions\n",
        "        review_text = \" \".join(review_text.split())\n",
        "        review_text = ct.fix(review_text)\n",
        "        # remove non-alphabetical chars\n",
        "        regex = re.compile('[^a-zA-Z]')\n",
        "        review_text = regex.sub(' ', review_text)\n",
        "        # convert to lower case\n",
        "        review_text = review_text.lower()\n",
        "        # exclude words not in w2v\n",
        "        review_text = \" \".join(review_text.split())\n",
        "        review_text = exclude_words_not_in_w2v(review_text)\n",
        "        # end of data processing\n",
        "        review_text = \" \".join(review_text.split())\n",
        "        # replace empty string with numpy's nan datatype\n",
        "        if review_text != \"\":                  \n",
        "            data_frame.loc[i, ['review_body']] = review_text\n",
        "        else:\n",
        "            data_frame.loc[i, ['review_body']] = np.nan\n",
        "    return data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uD_VePw9bpDi"
      },
      "outputs": [],
      "source": [
        "def data_prep(data):\n",
        "    prepared_data = []\n",
        "    for i in range (0,len(data)):\n",
        "        words_list = data[i].split()\n",
        "        vector_sum = np.zeros((300,))\n",
        "        total_word = len(words_list)\n",
        "        for word in words_list:\n",
        "            vector_sum = vector_sum + wv[word]  \n",
        "                \n",
        "        prepared_data.append(vector_sum/total_word)\n",
        "        \n",
        "    return np.array(prepared_data)\n",
        "\"\"\"\n",
        "def data_prep2(data):\n",
        "    prepared_data = []\n",
        "    for i in range(0, len(data)):\n",
        "        words_list = data[i].split()\n",
        "        concat_vector = []\n",
        "        index = 0\n",
        "        for word in words_list:\n",
        "            if index > 9:\n",
        "                break\n",
        "            if word in wv:\n",
        "                concat_vector.append(wv[word])\n",
        "                index += 1\n",
        "        while len(concat_vector) < 10:\n",
        "            concat_vector.append(np.zeros(300))\n",
        "        prepared_data.append(np.concatenate(concat_vector, axis=None))\n",
        "    prepared_data = np.array(prepared_data, dtype=object)\n",
        "    prepared_data = np.reshape(prepared_data, (prepared_data.shape[0], 3000))\n",
        "    return prepared_data\n",
        "\"\"\" \n",
        "#LESS RAM\n",
        "def data_prep2(data):\n",
        "    prepared_data = np.zeros((len(data), 3000))\n",
        "    for i in range(0, len(data)):\n",
        "        words_list = data[i].split()\n",
        "        index = 0\n",
        "        for word in words_list:\n",
        "            if index > 9:\n",
        "                break\n",
        "            if word in wv:\n",
        "                prepared_data[i][index*300:(index+1)*300] = wv[word]\n",
        "                index += 1\n",
        "    return prepared_data\n",
        "\n",
        "def data_prep3(data):\n",
        "    total_reviews = len(data)\n",
        "    max_review_length = 20\n",
        "    input_sequence = torch.zeros((total_reviews, max_review_length, 300))\n",
        "\n",
        "    # iterate over the reviews\n",
        "    for i in range(total_reviews):\n",
        "    # convert the review into a list of words\n",
        "        words = data[i].split()\n",
        "\n",
        "    # iterate over the words in the review and convert them to their corresponding word vectors\n",
        "        for j in range(min(len(words), max_review_length)):\n",
        "            if words[j] in wv.vocab:\n",
        "                input_sequence[i][j] = torch.from_numpy(wv[words[j]])\n",
        "            else:\n",
        "                input_sequence[i][j] = torch.zeros(300)\n",
        "    \n",
        "    return input_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNfflN3GClrH"
      },
      "outputs": [],
      "source": [
        "# Print the training result\n",
        "def generate_report(y_test, y_pred):\n",
        "    report = classification_report(y_test, y_pred, zero_division=1, output_dict=True)\n",
        "    print(\"Class 1 Precision: \" + str(report[str(0)]['precision']) + \", Class 1 Recall: \" + str(\n",
        "        report[str(0)]['recall']) + \", Class 1 f1-score: \" + str(report[str(0)]['f1-score']))\n",
        "    print(\"Class 2 Precision: \" + str(report[str(1)]['precision']) + \", Class 2 Recall: \" + str(\n",
        "        report[str(1)]['recall']) + \", Class 2 f1-score: \" + str(report[str(1)]['f1-score']))\n",
        "    print(\"Class 3 Precision: \" + str(report[str(2)]['precision']) + \", Class 3 Recall: \" + str(\n",
        "        report[str(2)]['recall']) + \", Class 3 f1-score: \" + str(report[str(2)]['f1-score']))\n",
        "    print(\"Average Precision: \" + str(report['macro avg']['precision']) + \", Averagage Recall: \" + str(\n",
        "        report['macro avg']['recall']) + \", Averagage f1-score: \" + str(\n",
        "        report['macro avg']['f1-score']))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJjEbxDpgDbZ"
      },
      "source": [
        "#Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Erwe56YOfY9-"
      },
      "outputs": [],
      "source": [
        "RANDOM_SAMPLE_SIZE = 20000\n",
        "sym_spell = init_spell_checker()\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORd-eXhXlpnM"
      },
      "source": [
        "#Prepare Balanced Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdT_M4WOlxZT"
      },
      "outputs": [],
      "source": [
        "# reading data\n",
        "df = pd.read_pickle(\"/content/drive/MyDrive/Dataset/data.pkl\")\n",
        "df = init_data(df).reset_index(drop=True)\n",
        "\n",
        "# 3-classes dataset\n",
        "class1_df = df[df['star_rating'] <= 2].sample(RANDOM_SAMPLE_SIZE)\n",
        "class2_df = df[df['star_rating'] == 3].sample(RANDOM_SAMPLE_SIZE)\n",
        "class3_df = df[df['star_rating'] >= 4].sample(RANDOM_SAMPLE_SIZE)\n",
        "\n",
        "balanced_df = pd.concat([class1_df, class2_df, class3_df]).reset_index(drop=True)\n",
        "cleaned_balanced_df = data_cleaning(balanced_df)\n",
        "cleaned_balanced_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_balanced_df = pd.read_pickle(\"/content/drive/MyDrive/Dataset/cleaned_data.pkl\")"
      ],
      "metadata": {
        "id": "yXhyVSr5CEJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFVTb25Gy-3p"
      },
      "source": [
        "#Task 2a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llGJOfcO9D3Z",
        "outputId": "9223a1c9-1c57-4f19-f1ae-4877c29080e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ice + sport - walk ~= ('hockey', 0.5072677135467529)\n",
            "gas + dangerous - stable ~= ('natural_gas', 0.4578143358230591)\n",
            "cold + rain - sun ~= ('wet_weather', 0.5952470302581787)\n"
          ]
        }
      ],
      "source": [
        "# 3 examples using word2vec-google-news-300\n",
        "example_1 = wv.most_similar(positive=['ice','sport'], negative=['walk'])\n",
        "example_2 = wv.most_similar(positive=['gas', 'dangerous'], negative=['stable'])\n",
        "example_3 = wv.most_similar(positive=['cold', 'rain'], negative=['sun'])\n",
        "print(\"ice + sport - walk ~= \" + str(example_1[0]))\n",
        "print(\"gas + dangerous - stable ~= \" + str(example_2[0]))\n",
        "print(\"cold + rain - sun ~= \" + str(example_3[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI-ZqGu4FP_U"
      },
      "source": [
        "#Task 2b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6vQkLkPFVY9"
      },
      "outputs": [],
      "source": [
        "sentences = cleaned_balanced_df[\"review_body\"].tolist()\n",
        "sentences_training = [index.split() for index in sentences ]\n",
        "# Train Word2vec model with Amazon review data\n",
        "my_word2vec = gensim.models.Word2Vec(sentences_training , size=300, window=13, min_count=9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvNgc7UDWuU4",
        "outputId": "31eb0ff4-3306-45ff-ef03-76b0f03a6f78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ice + sport - walk ~= ('amber', 0.7013514041900635)\n",
            "gas + dangerous - stable ~= ('practices', 0.6267540454864502)\n",
            "cold + rain - sun ~= ('freshener', 0.6289527416229248)\n"
          ]
        }
      ],
      "source": [
        "# 3 examples using provided Amazon review\n",
        "example_1 = my_word2vec.wv.most_similar(positive=['ice','sport'], negative=['walk'])\n",
        "example_2 = my_word2vec.wv.most_similar(positive=['gas', 'dangerous'], negative=['stable'])\n",
        "example_3 = my_word2vec.wv.most_similar(positive=['cold', 'rain'], negative=['sun'])\n",
        "print(\"ice + sport - walk ~= \" + str(example_1[0]))\n",
        "print(\"gas + dangerous - stable ~= \" + str(example_2[0]))\n",
        "print(\"cold + rain - sun ~= \" + str(example_3[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6pboK305N_e"
      },
      "source": [
        "#Task 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Xjd3tX8AC3"
      },
      "source": [
        "####Split dataset into Training and Testing Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfS9-Wlg5RRj"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(cleaned_balanced_df['review_body'], cleaned_balanced_df['star_rating'], test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjnjmlLdI_0k"
      },
      "source": [
        "#### Convert Datasets to Correct Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "olt4nAY-8fYu"
      },
      "outputs": [],
      "source": [
        "X_train_np = data_prep(X_train.to_numpy()) \n",
        "X_test_np = data_prep(X_test.to_numpy()) \n",
        "y_train_np = y_train.to_numpy()\n",
        "y_test_np =  y_test.to_numpy()\n",
        "\n",
        "X_train_np_2 = data_prep2(X_train.to_numpy()) \n",
        "X_test_np_2 = data_prep2(X_test.to_numpy()) \n",
        "\n",
        "X_train_np_3 = data_prep3(X_train.to_numpy()) \n",
        "X_test_np_3 = data_prep3(X_test.to_numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1E5uguBvmbx"
      },
      "source": [
        "#Cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Sr88X2njkW-t"
      },
      "outputs": [],
      "source": [
        "# task 4\n",
        "with open('/content/drive/MyDrive/Dataset/X_train.npy', 'wb') as f:\n",
        "    np.save(f, X_train_np)\n",
        "with open('/content/drive/MyDrive/Dataset/X_test.npy', 'wb') as f1:\n",
        "    np.save(f1, X_test_np)\n",
        "with open('/content/drive/MyDrive/Dataset/y_train.npy', 'wb') as f2:\n",
        "    np.save(f2, y_train_np)\n",
        "with open('/content/drive/MyDrive/Dataset/y_test.npy', 'wb') as f3:\n",
        "    np.save(f3, y_test_np)\n",
        "\n",
        "with open('/content/drive/MyDrive/Dataset/X_train_2.npy', 'wb') as f:\n",
        "    np.save(f, X_train_np_2)\n",
        "with open('/content/drive/MyDrive/Dataset/X_test_2.npy', 'wb') as f1:\n",
        "    np.save(f1, X_test_np_2)\n",
        "# task 5\n",
        "with open('/content/drive/MyDrive/Dataset/X_train_3.npy', 'wb') as f:\n",
        "    np.save(f, X_train_np_3)\n",
        "with open('/content/drive/MyDrive/Dataset/X_test_3.npy', 'wb') as f1:\n",
        "    np.save(f1, X_test_np_3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yorHSUWzueGb"
      },
      "source": [
        "#### Train Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FrII3Njn59sB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "e482d04f-2070-44f4-d3af-04903eb9a72b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ea660741488a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf_perceptron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_perceptron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred_perceptron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_perceptron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgenerate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_perceptron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'generate_report' is not defined"
          ]
        }
      ],
      "source": [
        "clf_perceptron = Perceptron()\n",
        "clf_perceptron = clf_perceptron.fit(X_train_np, y_train_np)\n",
        "y_pred_perceptron = clf_perceptron.predict(X_test_np)\n",
        "generate_report(y_test_np, y_pred_perceptron)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R86eteEjui1i"
      },
      "source": [
        "####Train Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIOVPay6ul8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b45b9b55-b3ed-4d60-939e-9964bc84eb17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 Precision: 0.6570754716981132, Class 1 Recall: 0.6944167497507477, Class 1 f1-score: 0.6752302472127969\n",
            "Class 2 Precision: 0.5934065934065934, Class 2 Recall: 0.5480198019801981, Class 2 f1-score: 0.5698108351563507\n",
            "Class 3 Precision: 0.713220675944334, Class 3 Recall: 0.7278721785442557, Class 3 f1-score: 0.7204719467804696\n",
            "Average Precision: 0.6545675803496802, Averagage Recall: 0.6567695767584005, Averagage f1-score: 0.655171009716539\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf_linear_svc = LinearSVC()\n",
        "clf_linear_svc = clf_linear_svc.fit(X_train_np, y_train_np)\n",
        "y_pred_linear_svc = clf_linear_svc.predict(X_test_np)\n",
        "generate_report(y_test_np, y_pred_linear_svc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgUpxydewA8S"
      },
      "source": [
        "##Read Cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d-U7U5GrF4JF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48bfa3f3-d5bd-414b-8e75-33d9576d2dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "with open('/content/drive/MyDrive/Dataset/X_train.npy', 'rb') as f:\n",
        "    X_train_np_c = np.load(f,allow_pickle=True)\n",
        "with open('/content/drive/MyDrive/Dataset/y_train.npy', 'rb') as f:\n",
        "    y_train_np_c = np.load(f, allow_pickle=True)\n",
        "with open('/content/drive/MyDrive/Dataset/X_test.npy', 'rb') as f:\n",
        "    X_test_np_c = np.load(f, allow_pickle=True)\n",
        "with open('/content/drive/MyDrive/Dataset/y_test.npy', 'rb') as f:\n",
        "    y_test_np_c = np.load(f, allow_pickle=True)  \n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Dataset/X_train_2.npy', 'rb') as f:\n",
        "    X_train_np_2_c = np.load(f,allow_pickle=True)\n",
        "with open('/content/drive/MyDrive/Dataset/X_test_2.npy', 'rb') as f:\n",
        "    X_test_np_2_c = np.load(f, allow_pickle=True)\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Dataset/X_train_3.npy', 'rb') as f:\n",
        "    X_train_np_3_c = np.load(f,allow_pickle=True)\n",
        "with open('/content/drive/MyDrive/Dataset/X_test_3.npy', 'rb') as f:\n",
        "    X_test_np_3_c = np.load(f, allow_pickle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulRHZC8pDVZG"
      },
      "source": [
        "#Task 4a"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Define functions"
      ],
      "metadata": {
        "id": "Hhwy3lA7VpCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Output Evaluation an MLP \n",
        "def Train_an_MLP_and_eval(input_size, hidden_1, hidden_2, use_batchnom,dropout_p, train,validation,test,lr =0.001,wd=0.0,es_num=10,num_epoch=500):\n",
        "    mlp = MLP(input_size, hidden_1, hidden_2, use_batchnom,dropout_p)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.RAdam(mlp.parameters(),lr=lr, weight_decay=wd)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    counter = 0\n",
        "    train_list = []\n",
        "    valid_list = []\n",
        "    test_list = []\n",
        "\n",
        "    lowest_valid_loss = float('inf')\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(0, num_epoch): \n",
        "        train_loss = 0.0\n",
        "        print(epoch)##\n",
        "        for i, data in enumerate(train, 0):\n",
        "            inputs, targets = data\n",
        "          \n",
        "            optimizer.zero_grad()\n",
        "            outputs = mlp(inputs)\n",
        "            targets = targets.type(torch.LongTensor)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        \n",
        "        # record train loss\n",
        "        train_list.append(train_loss / len(train))\n",
        "\n",
        "        # record validation loss\n",
        "        valid_loss = 0.0\n",
        "        mlp.eval()  \n",
        "        for i, data in enumerate(validation, 0):\n",
        "            inputs, targets = data\n",
        "            outputs = mlp(inputs)\n",
        "            targets = targets.type(torch.LongTensor)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            valid_loss += loss.item()\n",
        "        valid_list.append(valid_loss / len(validation))\n",
        "        \n",
        "        # update lowest validation loss\n",
        "        if lowest_valid_loss > valid_loss / len(validation):\n",
        "            lowest_valid_loss = valid_loss / len(validation)\n",
        "\n",
        "        # record test loss\n",
        "        mlp.eval()  \n",
        "        testing_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test:\n",
        "                output = mlp(data)\n",
        "                target = target.type(torch.LongTensor)\n",
        "                loss = loss_function(output, target)\n",
        "                testing_loss += loss.item() * data.size(0)\n",
        "        testing_loss /= len(test.dataset)\n",
        "        test_list.append(testing_loss)\n",
        "\n",
        "        # early stopping\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            counter = 0\n",
        "            torch.save(mlp.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= es_num:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "    print(\"Lowest Valid Loss = \" + str(lowest_valid_loss))\n",
        "    \n",
        "    # Use the best model obtained from the early stopping process\n",
        "    mlp.load_state_dict(torch.load('best_model.pt'))\n",
        "    plot_loss(train_list, test_list, valid_list)    \n",
        "    test_acc(mlp, test)\n"
      ],
      "metadata": {
        "id": "DdbpFIHv78aE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader,TensorDataset,random_split\n",
        "from torchvision import transforms,datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def test_acc(model, dataloader):\n",
        "    model.eval()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, labels in dataloader:\n",
        "            outputs = model(data)\n",
        "            # Calculate the predicted labels\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()  \n",
        "    accuracy = 100 * correct / total      \n",
        "    print('Test accuracy: {:.16f}%'.format(accuracy))\n",
        "\n",
        "def plot_loss(train_loss, test_loss, val_loss):\n",
        "    epochs = len(train_loss)\n",
        "    x = range(epochs)\n",
        "\n",
        "    plt.plot(x, train_loss, label='Training Loss')\n",
        "    plt.plot(x, test_loss, label='Testing Loss')\n",
        "    plt.plot(x, val_loss, label='Validation Loss')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "_c0tOtRi6zoi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhg2zR1HXgSc"
      },
      "source": [
        "####Setup Dataloaders for Task 4a and 4b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H_fYexDyPon_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9913f8-0106-41a0-818e-47a33c4b24b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#####   Dataloaders for task 4a #####\n",
        "BATCH_SIZE = 64\n",
        "X_train_tensor = torch.Tensor(X_train_np_c)\n",
        "X_test_tensor  = torch.Tensor(X_test_np_c)\n",
        "y_train_tensor = torch.Tensor(y_train_np_c)\n",
        "y_test_tensor = torch.Tensor(y_test_np_c)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor,y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor,y_test_tensor)\n",
        "\n",
        "train_dataset, validation_dataset = random_split(train_dataset,[0.9,0.1])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True) \n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True) \n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True) \n",
        "\n",
        "#####   Dataloaders for task 4b #####\n",
        "BATCH_SIZE_2 = 32\n",
        "\n",
        "X_train_tensor_2 = torch.Tensor(X_train_np_2_c.astype('float32'))\n",
        "X_test_tensor_2  = torch.Tensor(X_test_np_2_c.astype('float32'))\n",
        "\n",
        "train_dataset_2 = TensorDataset(X_train_tensor_2,y_train_tensor)\n",
        "test_dataset_2 = TensorDataset(X_test_tensor_2,y_test_tensor)\n",
        "\n",
        "train_dataset_2, validation_dataset_2 = random_split(train_dataset_2,[0.9,0.1])\n",
        "\n",
        "train_dataloader_2 = DataLoader(train_dataset_2, batch_size=BATCH_SIZE_2, shuffle=True) \n",
        "test_dataloader_2 = DataLoader(test_dataset_2, batch_size=BATCH_SIZE_2, shuffle=True) \n",
        "validation_dataloader_2= DataLoader(validation_dataset_2, batch_size=BATCH_SIZE_2, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####MLP constructor"
      ],
      "metadata": {
        "id": "RTmdvbCEVxrt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hBReo9qTbskK"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_1, hidden_2, use_batchnorm, dropout_p=0.0, output_size= 3):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        layers.append(nn.Flatten())\n",
        "        layers.append(nn.Linear(input_size, hidden_1))\n",
        "        if use_batchnorm:\n",
        "            layers.append(nn.BatchNorm1d(hidden_1))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(dropout_p))\n",
        "        layers.append(nn.Linear(hidden_1, hidden_2))\n",
        "        if use_batchnorm:\n",
        "            layers.append(nn.BatchNorm1d(hidden_2))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(dropout_p))\n",
        "        layers.append(nn.Linear(hidden_2, output_size))\n",
        "        \n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Train MLP 4a"
      ],
      "metadata": {
        "id": "rKKbI0K2V5hz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "r71car5tqg00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "7af61506-3307-4908-91ca-d4b6baee6e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-695dde0cc44d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain_an_MLP_and_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-db1d7a6740df>\u001b[0m in \u001b[0;36mTrain_an_MLP_and_eval\u001b[0;34m(input_size, hidden_1, hidden_2, use_batchnom, dropout_p, train, validation, test, lr, es_num, num_epoch)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/radam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             radam(params_with_grad,\n\u001b[0m\u001b[1;32m    131\u001b[0m                   \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                   \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/radam.py\u001b[0m in \u001b[0;36mradam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, state_steps, foreach, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_radam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    180\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/radam.py\u001b[0m in \u001b[0;36m_single_tensor_radam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, state_steps, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# correcting bias for the first moving moment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Train_an_MLP_and_eval(300,100,10,True,0.5,train_dataloader,validation_dataloader,test_dataloader,wd=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train MLP 4b"
      ],
      "metadata": {
        "id": "DVtSotCOrAwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_an_MLP_and_eval(3000,100,10,True,0.5,train_dataloader_2,validation_dataloader_2,test_dataloader_2,wd = 0.01)"
      ],
      "metadata": {
        "id": "-khD3tmcjn2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "outputId": "40e0b345-c798-43a4-de42-e7512af3a95a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "Early stopping\n",
            "Lowest Valid Loss = 0.8917805906136831\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 57.1571488120050049%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5"
      ],
      "metadata": {
        "id": "zNYqnVUkmHxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Prepare Dataloaders for RNNs"
      ],
      "metadata": {
        "id": "TxBlNCjcDehN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE_3 = 32\n",
        "\n",
        "X_train_tensor_3 = torch.Tensor(X_train_np_3_c.astype('float32'))\n",
        "X_test_tensor_3  = torch.Tensor(X_test_np_3_c.astype('float32'))\n",
        "\n",
        "train_dataset_3 = TensorDataset(X_train_tensor_3,y_train_tensor)\n",
        "test_dataset_3 = TensorDataset(X_test_tensor_3,y_test_tensor)\n",
        "\n",
        "train_dataset_3, validation_dataset_3 = random_split(train_dataset_3,[0.9,0.1])\n",
        "\n",
        "train_dataloader_3 = DataLoader(train_dataset_3, batch_size=BATCH_SIZE_3, shuffle=True) \n",
        "test_dataloader_3 = DataLoader(test_dataset_3, batch_size=BATCH_SIZE_3, shuffle=True) \n",
        "validation_dataloader_3= DataLoader(validation_dataset_3, batch_size=BATCH_SIZE_3, shuffle=True)\n"
      ],
      "metadata": {
        "id": "diajJR5AIUU4"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Simple RNN Constructor for Task 5a"
      ],
      "metadata": {
        "id": "oZWk2uxdlHAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, output_dim):\n",
        "        super(RNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_dim, hid_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, hidden = self.rnn(x)\n",
        "        out = self.fc(hidden.squeeze(0))\n",
        "        return out\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, output_dim, dropout=0.5, recurrent_dropout=0.2):\n",
        "        super(GRU, self).__init__()\n",
        "        self.gru = nn.GRU(input_dim, hid_dim, batch_first=True, dropout=dropout, num_layers=3, bidirectional=True)\n",
        "        self.fc = nn.Linear(hid_dim * 2 , output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape = (batch_size, seq_len, input_dim)\n",
        "        output, hidden = self.gru(x)\n",
        "        # output.shape = (batch_size, seq_len, hid_dim * 2)\n",
        "        # hidden.shape = (4, batch_size, hid_dim)\n",
        "\n",
        "        # average across the sequence length\n",
        "        output = torch.mean(output, dim=1)\n",
        "        # output.shape = (batch_size, hid_dim * 2)\n",
        "\n",
        "        out = self.fc(output)\n",
        "        # out.shape = (batch_size, output_dim)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "lZt2rhIYM0C2"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNN(300, 20, 3)\n",
        "gru = GRU(300, 20, 3)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.RAdam(gru.parameters())\n",
        "\n",
        "best_loss = float('inf')\n",
        "counter = 0\n",
        "train_list = []\n",
        "valid_list = []\n",
        "test_list = []\n",
        "lowest_valid_loss = float('inf')\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(0,num_epochs):\n",
        "    print(epoch)\n",
        "    train_loss = 0.0\n",
        "    for i, batch in enumerate(train_dataloader_3, 0):\n",
        "        # Get the input and target tensors from the batch\n",
        "        inputs, targets = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = gru(inputs)\n",
        "        #targets = torch.eye(3)[targets.long()] ########### For gru\n",
        "        targets = targets.type(torch.LongTensor)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    # record train loss\n",
        "    train_list.append(train_loss / len(train_dataloader_3))\n",
        "\n",
        "    # record validation loss\n",
        "    valid_loss = 0.0\n",
        "    gru.eval()  \n",
        "    for i, data in enumerate(validation_dataloader_3, 0):\n",
        "        inputs, targets = data\n",
        "        outputs = gru(inputs)\n",
        "        targets = targets.type(torch.LongTensor)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        valid_loss += loss.item()\n",
        "    valid_list.append(valid_loss / len(validation_dataloader_3))\n",
        "    print(valid_loss / len(validation_dataloader_3))\n",
        "    # update lowest validation loss\n",
        "    if lowest_valid_loss > valid_loss / len(validation_dataloader_3):\n",
        "        lowest_valid_loss = valid_loss / len(validation_dataloader_3)\n",
        "\n",
        "     # record test loss\n",
        "    gru.eval()  \n",
        "    testing_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_dataloader_3:\n",
        "            output = gru(data)\n",
        "            target = target.type(torch.LongTensor)\n",
        "            loss = loss_function(output, target)\n",
        "            testing_loss += loss.item() * data.size(0)\n",
        "    testing_loss /= len(test_dataloader_3.dataset)\n",
        "    test_list.append(testing_loss)\n",
        "\n",
        "    # early stopping\n",
        "    if valid_loss < best_loss:\n",
        "        best_loss = valid_loss\n",
        "        counter = 0\n",
        "        torch.save(gru.state_dict(), 'best_model.pt')\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= 10:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "print(\"Lowest Valid Loss = \" + str(lowest_valid_loss)) \n",
        "# Use the best model obtained from the early stopping process\n",
        "gru.load_state_dict(torch.load('best_model.pt'))\n",
        "plot_loss(train_list, test_list, valid_list)    \n",
        "test_acc(gru, test_dataloader_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "id": "0QmpZy5DRwiw",
        "outputId": "7d4674b8-7bac-45a6-fd8a-201c72913669"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0.8612276494503022\n",
            "1\n",
            "0.817803579568863\n",
            "2\n",
            "0.7883851397037506\n",
            "3\n",
            "0.7646399819850922\n",
            "4\n",
            "0.7487832353512446\n",
            "5\n",
            "0.7456901339689891\n",
            "6\n",
            "0.7374881166219711\n",
            "7\n",
            "0.7841561663150788\n",
            "8\n",
            "0.7446760529279709\n",
            "9\n",
            "0.7630399753650029\n",
            "10\n",
            "0.7623692733049393\n",
            "11\n",
            "0.7749565668900807\n",
            "12\n",
            "0.7710569697618485\n",
            "13\n",
            "0.7956694318850835\n",
            "14\n",
            "0.8238165672620138\n",
            "15\n",
            "0.8200505179166794\n",
            "16\n",
            "0.8539878726005554\n",
            "Early stopping\n",
            "Lowest Valid Loss = 0.7374881166219711\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 67.3947478115881609%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####GRU Constructor for Task 5b"
      ],
      "metadata": {
        "id": "66vyKCSMlL1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyper Tuning"
      ],
      "metadata": {
        "id": "miMjGC2603lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def grid_search(train_dataloader, validation_dataloader, test_dataloader, learning_rate_list, weight_decay_list, dropout_p_list, use_bn_list, activation_list):\n",
        "    best_loss = float('inf')\n",
        "    best_lr = None\n",
        "    best_wd = None\n",
        "    best_dp = None\n",
        "    best_bn = None\n",
        "    best_activation = None\n",
        "    \n",
        "    for lr in learning_rate_list:\n",
        "        for wd in weight_decay_list:\n",
        "            for dp in dropout_p_list:\n",
        "                for bn in use_bn_list:\n",
        "                    for activation in activation_list:\n",
        "                        mlp = MLP2(dropout_p=dp, use_bn=bn, activation=activation)\n",
        "                        loss_function = nn.CrossEntropyLoss()\n",
        "                        optimizer = torch.optim.RAdam(mlp.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "                        train_list = []\n",
        "                        valid_list = []\n",
        "                        test_list = []\n",
        "\n",
        "                        patience = 10\n",
        "                        counter = 0\n",
        "                        lowest_valid_loss = 100\n",
        "\n",
        "                        for epoch in range(0, 1000):\n",
        "                            train_loss = 0.0\n",
        "                            for i, data in enumerate(train_dataloader, 0):\n",
        "                                inputs, targets = data\n",
        "\n",
        "                                optimizer.zero_grad()\n",
        "                                outputs = mlp(inputs)\n",
        "                                targets = targets.type(torch.LongTensor)\n",
        "                                loss = loss_function(outputs, targets)\n",
        "                                loss.backward()\n",
        "                                optimizer.step()\n",
        "                                train_loss += loss.item()\n",
        "\n",
        "                            # record train loss\n",
        "                            train_list.append(train_loss / len(train_dataloader))\n",
        "\n",
        "                            # record validation loss\n",
        "                            valid_loss = 0.0\n",
        "                            mlp.eval()\n",
        "                            for i, data in enumerate(validation_dataloader, 0):\n",
        "                                inputs, targets = data\n",
        "                                outputs = mlp(inputs)\n",
        "                                targets = targets.type(torch.LongTensor)\n",
        "                                loss = loss_function(outputs, targets)\n",
        "                                valid_loss += loss.item()\n",
        "                            valid_list.append(valid_loss / len(validation_dataloader))\n",
        "\n",
        "                            # record test loss\n",
        "                            mlp.eval()\n",
        "                            testing_loss = 0.0\n",
        "                            with torch.no_grad():\n",
        "                                for data, target in test_dataloader:\n",
        "                                    output = mlp(data)\n",
        "                                    target = target.type(torch.LongTensor)\n",
        "                                    loss = loss_function(output, target)\n",
        "                                    testing_loss += loss.item() * data.size(0)\n",
        "\n",
        "                            testing_loss /= len(test_dataloader.dataset)\n",
        "                            test_list.append(testing_loss)\n",
        "\n",
        "                            # early stopping\n",
        "                            if valid_loss / len(validation_dataloader) < best_loss:\n",
        "                                best_loss = valid_loss / len(validation_dataloader)\n",
        "                                best_lr = lr\n",
        "                                best_wd = wd\n",
        "                                best_dp = dp\n",
        "                                best_bn = bn\n",
        "                                best_activation = activation\n",
        "                                counter = 0\n",
        "                                torch.save(mlp.state_dict(), 'best_model.pt')\n",
        "                            else:\n",
        "                                counter += 1\n",
        "                                if counter >= patience:\n",
        "                                    break\n",
        "\n",
        "                        # Use the best model obtained from the early stopping process\n",
        "                        mlp.load_state_dict(torch.load('best_model.pt'))\n",
        "\n",
        "\n",
        "    print(\"Grid search finished.\")\n",
        "    print(f\"Best hyperparameters: lr={best_lr}, wd={best_wd}, dp={best_dp}, bn={best_bn}, activation={best_activation}\")\n",
        "    print(f\"Best validation loss: {best_loss}\")\n",
        "    print(f\"Test accuracy: {test_acc(mlp, test_dataloader)}\")\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "S00GTnwfKu5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916eadb1-05f8-4dce-991c-7157897ddc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef grid_search(train_dataloader, validation_dataloader, test_dataloader, learning_rate_list, weight_decay_list, dropout_p_list, use_bn_list, activation_list):\\n    best_loss = float(\\'inf\\')\\n    best_lr = None\\n    best_wd = None\\n    best_dp = None\\n    best_bn = None\\n    best_activation = None\\n    \\n    for lr in learning_rate_list:\\n        for wd in weight_decay_list:\\n            for dp in dropout_p_list:\\n                for bn in use_bn_list:\\n                    for activation in activation_list:\\n                        mlp = MLP2(dropout_p=dp, use_bn=bn, activation=activation)\\n                        loss_function = nn.CrossEntropyLoss()\\n                        optimizer = torch.optim.RAdam(mlp.parameters(), lr=lr, weight_decay=wd)\\n\\n                        train_list = []\\n                        valid_list = []\\n                        test_list = []\\n\\n                        patience = 10\\n                        counter = 0\\n                        lowest_valid_loss = 100\\n\\n                        for epoch in range(0, 1000):\\n                            train_loss = 0.0\\n                            for i, data in enumerate(train_dataloader, 0):\\n                                inputs, targets = data\\n\\n                                optimizer.zero_grad()\\n                                outputs = mlp(inputs)\\n                                targets = targets.type(torch.LongTensor)\\n                                loss = loss_function(outputs, targets)\\n                                loss.backward()\\n                                optimizer.step()\\n                                train_loss += loss.item()\\n\\n                            # record train loss\\n                            train_list.append(train_loss / len(train_dataloader))\\n\\n                            # record validation loss\\n                            valid_loss = 0.0\\n                            mlp.eval()\\n                            for i, data in enumerate(validation_dataloader, 0):\\n                                inputs, targets = data\\n                                outputs = mlp(inputs)\\n                                targets = targets.type(torch.LongTensor)\\n                                loss = loss_function(outputs, targets)\\n                                valid_loss += loss.item()\\n                            valid_list.append(valid_loss / len(validation_dataloader))\\n\\n                            # record test loss\\n                            mlp.eval()\\n                            testing_loss = 0.0\\n                            with torch.no_grad():\\n                                for data, target in test_dataloader:\\n                                    output = mlp(data)\\n                                    target = target.type(torch.LongTensor)\\n                                    loss = loss_function(output, target)\\n                                    testing_loss += loss.item() * data.size(0)\\n\\n                            testing_loss /= len(test_dataloader.dataset)\\n                            test_list.append(testing_loss)\\n\\n                            # early stopping\\n                            if valid_loss / len(validation_dataloader) < best_loss:\\n                                best_loss = valid_loss / len(validation_dataloader)\\n                                best_lr = lr\\n                                best_wd = wd\\n                                best_dp = dp\\n                                best_bn = bn\\n                                best_activation = activation\\n                                counter = 0\\n                                torch.save(mlp.state_dict(), \\'best_model.pt\\')\\n                            else:\\n                                counter += 1\\n                                if counter >= patience:\\n                                    break\\n\\n                        # Use the best model obtained from the early stopping process\\n                        mlp.load_state_dict(torch.load(\\'best_model.pt\\'))\\n\\n\\n    print(\"Grid search finished.\")\\n    print(f\"Best hyperparameters: lr={best_lr}, wd={best_wd}, dp={best_dp}, bn={best_bn}, activation={best_activation}\")\\n    print(f\"Best validation loss: {best_loss}\")\\n    print(f\"Test accuracy: {test_acc(mlp, test_dataloader)}\")\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader,TensorDataset,random_split\n",
        "from torchvision import transforms,datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\"\"\"\n",
        "class MLP2(nn.Module):\n",
        "    \n",
        "    def __init__(self, dropout_p=0.5, use_bn=True, activation=\"relu\"):\n",
        "        super().__init__()\n",
        "        hidden_1 = 100\n",
        "        hidden_2 = 10\n",
        "        \n",
        "        if use_bn:\n",
        "            self.layers = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(300, hidden_1),\n",
        "                nn.BatchNorm1d(hidden_1),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_p),\n",
        "                nn.Linear(hidden_1, hidden_2),\n",
        "                nn.BatchNorm1d(hidden_2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_p),\n",
        "                nn.Linear(hidden_2, 3),\n",
        "            )\n",
        "        else:\n",
        "            self.layers = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(300, hidden_1),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_p),\n",
        "                nn.Linear(hidden_1, hidden_2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_p),\n",
        "                nn.Linear(hidden_2, 3),\n",
        "            )\n",
        "        \n",
        "        if activation == \"relu\":\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == \"sigmoid\":\n",
        "            self.activation = nn.Sigmoid()\n",
        "        elif activation == \"tanh\":\n",
        "            self.activation = nn.Tanh()\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid activation: {activation}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "learning_rate_list = [0.001]\n",
        "weight_decay_list= [0.0,0.001,0.0001]\n",
        "dropout_p_list = [0.0,0.3,0.5,0.7]\n",
        "use_bn_list = [True]\n",
        "activation_list = [\"relu\",\"sigmoid\",\"tanh\"]\n",
        "\n",
        "\n",
        "grid_search(train_dataloader, validation_dataloader, test_dataloader, learning_rate_list, weight_decay_list, dropout_p_list, use_bn_list, activation_list)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qkg0MNpXOm4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09390edc-2cc0-4330-9d29-c89017b38008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass MLP2(nn.Module):\\n    \\n    def __init__(self, dropout_p=0.5, use_bn=True, activation=\"relu\"):\\n        super().__init__()\\n        hidden_1 = 100\\n        hidden_2 = 10\\n        \\n        if use_bn:\\n            self.layers = nn.Sequential(\\n                nn.Flatten(),\\n                nn.Linear(300, hidden_1),\\n                nn.BatchNorm1d(hidden_1),\\n                nn.ReLU(),\\n                nn.Dropout(dropout_p),\\n                nn.Linear(hidden_1, hidden_2),\\n                nn.BatchNorm1d(hidden_2),\\n                nn.ReLU(),\\n                nn.Dropout(dropout_p),\\n                nn.Linear(hidden_2, 3),\\n            )\\n        else:\\n            self.layers = nn.Sequential(\\n                nn.Flatten(),\\n                nn.Linear(300, hidden_1),\\n                nn.ReLU(),\\n                nn.Dropout(dropout_p),\\n                nn.Linear(hidden_1, hidden_2),\\n                nn.ReLU(),\\n                nn.Dropout(dropout_p),\\n                nn.Linear(hidden_2, 3),\\n            )\\n        \\n        if activation == \"relu\":\\n            self.activation = nn.ReLU()\\n        elif activation == \"sigmoid\":\\n            self.activation = nn.Sigmoid()\\n        elif activation == \"tanh\":\\n            self.activation = nn.Tanh()\\n        else:\\n            raise ValueError(f\"Invalid activation: {activation}\")\\n\\n    def forward(self, x):\\n        x = self.layers(x)\\n        x = self.activation(x)\\n        return x\\n\\nlearning_rate_list = [0.001]\\nweight_decay_list= [0.0,0.001,0.0001]\\ndropout_p_list = [0.0,0.3,0.5,0.7]\\nuse_bn_list = [True]\\nactivation_list = [\"relu\",\"sigmoid\",\"tanh\"]\\n\\n\\ngrid_search(train_dataloader, validation_dataloader, test_dataloader, learning_rate_list, weight_decay_list, dropout_p_list, use_bn_list, activation_list)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "miMjGC2603lr"
      ],
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}